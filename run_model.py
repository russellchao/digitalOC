import pandas as pd
import numpy as np

from typing import Dict, Any, List

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

from parse_personnel import add_personnel_features
from add_participation_features import add_participation_features


def train_run_models() -> Dict[str, Dict[str, Any]]:
    """
    Trains tendency models ('run_gap', 'run_location')
    using all available situational, personnel, and
    formation features.
    """

    # 1. data loading
    try:
        pbp_files: List[pd.DataFrame] = [
            pd.read_csv("Data/pbp_2024_0.csv", low_memory=False),
            pd.read_csv("Data/pbp_2024_1.csv", low_memory=False),
        ]
        df: pd.DataFrame = pd.concat(pbp_files, ignore_index=True)
    except FileNotFoundError:
        print("Error: Data files not found in 'Data/' directory. Exiting.")
        return {}

    df_filtered: pd.DataFrame = df[df["play_type"] == "run"].copy()

    if df_filtered.empty:
        print("No 'run' plays found. Exiting.")
        return {}

    # 1b. OPTIONAL participation / personnel merge
    try:
        part_df: pd.DataFrame = pd.read_csv(
            "Data/pbp_participation_2024.csv",
            low_memory=False,
        )
    except FileNotFoundError:
        print("Warning: participation file not found, skipping personnel/formation features.")
        part_df = None

    if part_df is not None:
        # figure out shared game key
        if "old_game_id" in df_filtered.columns and "old_game_id" in part_df.columns:
            game_key_col: str = "old_game_id"
        elif "game_id" in df_filtered.columns and "game_id" in part_df.columns:
            game_key_col = "game_id"
        else:
            print("Warning: no shared game id between PBP and participation; skipping personnel/formation.")
            part_df = None

    if part_df is not None:
        keep_cols: List[str] = [game_key_col, "play_id"]

        # only grab what we actually care about right now
        extra_part_cols: List[str] = [
            "offense_personnel",
            "defense_personnel",
            "offense_formation",
            "defenders_in_box",
        ]

        for col in extra_part_cols:
            if col in part_df.columns:
                keep_cols.append(col)

        part_df = part_df[keep_cols].drop_duplicates(subset=[game_key_col, "play_id"])

        df_filtered = pd.merge(
            df_filtered,
            part_df,
            on=[game_key_col, "play_id"],
            how="left",
        )

        # rename into what add_personnel_features expects
        df_filtered = df_filtered.rename(
            columns={
                "offense_personnel": "personnel_off",
                "defense_personnel": "personnel_def",
            }
        )

        # engineer numeric personnel and helper flags
        df_filtered = add_personnel_features(df_filtered)
        df_filtered = add_participation_features(df_filtered)

    # 2. pre-processing (same as group version)
    for col in ["temp", "wind"]:
        if col in df_filtered.columns:
            median_val: float = float(df_filtered[col].median())
            df_filtered[col] = df_filtered[col].fillna(median_val)

    # new situational features
    required_cols: List[str] = [
        "yardline_100",
        "goal_to_go",
        "ydstogo",
        "down",
        "quarter_seconds_remaining",
        "qtr",
        "score_differential",
    ]

    if all(col in df_filtered.columns for col in required_cols):
        df_filtered["is_redzone"] = (df_filtered["yardline_100"] <= 20).astype(int)
        df_filtered["is_goal_line"] = (
            (df_filtered["goal_to_go"] == 1) & (df_filtered["yardline_100"] <= 10)
        ).astype(int)
        df_filtered["is_short_yardage"] = (
            (df_filtered["ydstogo"] <= 2) & (df_filtered["down"] >= 3)
        ).astype(int)
        df_filtered["is_two_minute_drill"] = (
            (df_filtered["quarter_seconds_remaining"] <= 120)
            & (df_filtered["qtr"].isin([2, 4]))
        ).astype(int)
        df_filtered["is_close_game_late"] = (
            (df_filtered["qtr"] == 4)
            & (df_filtered["score_differential"].abs() <= 8)
        ).astype(int)

    # 3. define 'y' (target) for Stage 1: 'run_success'
    # THIS SECTION IS NO LONGER NEEDED FOR THE TENDENCY MODELS
    # if not all(col in df_filtered.columns for col in ["yards_gained", "ydstogo", "touchdown"]):
    #     print(
    #         "Error: Missing 'yards_gained', 'ydstogo', or 'touchdown'. "
    #         "Cannot create 'run_success' target. Exiting."
    #     )
    #     return {}
    #
    # is_first_down: pd.Series = (
    #     (df_filtered["yards_gained"] >= df_filtered["ydstogo"])
    #     & (df_filtered["yards_gained"].notna())
    # )
    # is_touchdown: pd.Series = df_filtered["touchdown"] == 1
    # y_sit: pd.Series = (is_first_down | is_touchdown).astype(int)
    # y_sit.name = "run_success"

    # 4. define 'X' (features) for all models

    # original base feature set from your group
    base_feature_columns: List[str] = [
        "down",
        "ydstogo",
        "yardline_100",
        "goal_to_go",
        "qtr",
        "quarter_seconds_remaining",
        "game_seconds_remaining",
        "score_differential",
        "posteam_timeouts_remaining",
        "defteam_timeouts_remaining",
        "shotgun",
        "no_huddle",
        "posteam",
        "defteam",
        "roof",
        "surface",
        "temp",
        "wind",
        "is_redzone",
        "is_goal_line",
        "is_short_yardage",
        "is_two_minute_drill",
        "is_close_game_late",
    ]

    # NEW: personnel numeric features (if created)
    personnel_numeric: List[str] = [
        "off_rb",
        "off_te",
        "off_wr",
        "def_dl",
        "def_lb",
        "def_db",
        "defenders_in_box",
    ]

    # NEW: personnel / formation categoricals
    personnel_categorical: List[str] = [
        "offense_formation",
        "off_group_bucket",
        "def_group_bucket",
    ]

    feature_columns: List[str] = (
        base_feature_columns + personnel_numeric + personnel_categorical
    )

    # fill numeric NaNs for personnel if present
    for num_col in personnel_numeric:
        if num_col in df_filtered.columns:
            df_filtered[num_col] = df_filtered[num_col].fillna(0)

    existing_features: List[str] = [
        col for col in feature_columns if col in df_filtered.columns
    ]
    X: pd.DataFrame = df_filtered[existing_features].copy()

    if X.empty:
        print("Error: No features found. Exiting.")
        return {}

    # encode categorical features
    categorical_cols: List[str] = [
        "posteam",
        "defteam",
        "roof",
        "surface",
        "qtr",
        "offense_formation",
        "off_group_bucket",
        "def_group_bucket",
    ]

    existing_categorical: List[str] = [
        col for col in categorical_cols if col in X.columns
    ]
    X_processed: pd.DataFrame = pd.get_dummies(
        X,
        columns=existing_categorical,
        drop_first=True,
    )

    # 5. Stage 1 model: predict run_success
    # WE ARE REMOVING THE 2-STAGE PIPELINE
    # The 'sit_model' is no longer needed to generate features
    # for the tendency models.
    print("--- Model Pipeline Simplification ---")
    print("Training tendency models directly on all features.")
    print(f"Total features being used: {len(X_processed.columns)}")

    # 6. Stage 2 models: predict tendencies
    trained_models: Dict[str, Dict[str, Any]] = {}
    target_columns: List[str] = ["run_gap", "run_location"]

    for target in target_columns:
        print(f"\nStarting model training for: {target}")

        if target not in df_filtered.columns:
            print(f"Warning: Target column '{target}' not found.")
            continue

        y_tend: pd.Series = df_filtered[target]

        # Clean NaNs from this *specific* target
        valid_indices = y_tend.dropna().index
        X_clean = X_processed.loc[valid_indices]
        y_clean = y_tend.loc[valid_indices]

        if X_clean.empty or y_clean.nunique() < 2:
            print(
                f"Warning: Not enough data or classes for '{target}' after cleaning. Skipping..."
            )
            continue
        
        # Create a single train/test split for this target
        X_train, X_test, y_train, y_test = train_test_split(
            X_clean,
            y_clean,
            test_size=0.2,
            random_state=42,
            stratify=y_clean
        )

        model: RandomForestClassifier = RandomForestClassifier(
            n_estimators=100,
            random_state=42,
        )
        model.fit(X_train, y_train)

        if not X_test.empty:
            y_pred: np.ndarray = model.predict(X_test)
            tend_accuracy: float = accuracy_score(y_test, y_pred)

            print(f"Model accuracy for '{target}': {tend_accuracy:.3f}")
            print(f"Classification report for '{target}':")
            labels: np.ndarray = np.union1d(y_test.unique(), y_pred)
            print(
                classification_report(
                    y_test,
                    y_pred,
                    labels=labels,
                    zero_division=0,
                )
            )

        print(f"Model training complete for: {target}")

        trained_models[target] = {
            "model": model,
            "columns": X_train.columns.tolist(),
        }

    # store situation model too
    # trained_models["situation"] = {
    #     "model": sit_model,
    #     "columns": X_sit_train.columns.tolist(),
    # }

    return trained_models


if __name__ == "__main__":
    print("Starting all run model training")
    all_models: Dict[str, Dict[str, Any]] = train_run_models()

    if all_models:
        print("\nAll model training complete")
        print(f"Trained {len(all_models)} models: {list(all_models.keys())}")
    else:
        print("\nModel training failed ---")